{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/home/hazem/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:301180)",
      "at w.execute (/home/hazem/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
      "at w.start (/home/hazem/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at t.CellExecutionQueue.executeQueuedCells (/home/hazem/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
      "at t.CellExecutionQueue.start (/home/hazem/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hazem/anaconda3/envs/anaconda_enviroment/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from models import ResNet18\n",
    "from client import Client\n",
    "from data import medmnist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weights(w):\n",
    "    \"\"\"\n",
    "    Returns the average of the wei'ghts.\n",
    "    \"\"\"\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for key in w_avg.keys():\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[key] += w[i][key]\n",
    "        w_avg[key] = torch.div(w_avg[key], len(w))\n",
    "    return w_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'function'>\n",
      "Using downloaded and verified file: ../../data/pathmnist/pathmnist.npz\n",
      "Using downloaded and verified file: ../../data/pathmnist/pathmnist.npz\n",
      "Using downloaded and verified file: ../../data/pathmnist/pathmnist.npz\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_CLIENTS = 100\n",
    "EPOCHS = 10\n",
    "FRACTION = 0.2\n",
    "EVERY = 1\n",
    "LOCAL_EPOCHS = 10\n",
    "DATA_POINTS_PER_USER = 100\n",
    "print(type(medmnist_dataset))\n",
    "train_dataset, test_dataset, clients, info = medmnist_dataset(name=\"PathMnist\", num_clients=NUM_CLIENTS, DATA_POINTS_PER_USER)\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899\n"
     ]
    }
   ],
   "source": [
    "print(len(clients[list(clients.keys())[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset PathMNIST (pathmnist)\n",
      "    Number of datapoints: 7180\n",
      "    Root location: ../../data/pathmnist\n",
      "    Split: test\n",
      "    Task: multi-class\n",
      "    Number of channels: 3\n",
      "    Meaning of labels: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n",
      "    Number of samples: {'train': 89996, 'val': 10004, 'test': 7180}\n",
      "    Description: The PathMNIST is based on a prior study for predicting survival from colorectal cancer histology slides, providing a dataset (NCT-CRC-HE-100K) of 100,000 non-overlapping image patches from hematoxylin & eosin stained histological images, and a test dataset (CRC-VAL-HE-7K) of 7,180 image patches from a different clinical center. The dataset is comprised of 9 types of tissues, resulting in a multi-class classification task. We resize the source images of 3×224×224 into 3×28×28, and split NCT-CRC-HE-100K into training and validation set with a ratio of 9:1. The CRC-VAL-HE-7K is treated as the test set.\n",
      "    License: CC BY 4.0\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-class\n"
     ]
    }
   ],
   "source": [
    "print(info[\"task\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = ResNet18(in_channels=n_channels, num_classes=n_classes)\n",
    "global_model.to(DEVICE)\n",
    "global_model.train()\n",
    "local_weights = []\n",
    "local_losses = []\n",
    "train_loss = []\n",
    "training_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899\n"
     ]
    }
   ],
   "source": [
    "print(len(clients[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/hazem/Basira-Internship/code/FederatedLearningPytorchHazem/src/client.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(image), torch.tensor(label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client 34\n",
      "<client.DatasetSplit object at 0x7feda7cc4d60>\n",
      "updating weights for client 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:16<?, ?it/s]\n",
      "  0%|          | 0/10 [00:16<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m local_model \u001b[38;5;241m=\u001b[39m Client(dataset\u001b[38;5;241m=\u001b[39mtrain_dataset, idxs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(clients[client_idx]),local_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, local_bs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, device\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdating weights for client \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m weights , loss \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglobal_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m local_weights\u001b[38;5;241m.\u001b[39mappend(copy\u001b[38;5;241m.\u001b[39mdeepcopy(weights)) \n\u001b[1;32m     15\u001b[0m local_losses\u001b[38;5;241m.\u001b[39mappend(copy\u001b[38;5;241m.\u001b[39mdeepcopy(loss))\n",
      "File \u001b[0;32m~/Basira-Internship/code/FederatedLearningPytorchHazem/src/client.py:64\u001b[0m, in \u001b[0;36mClient.update_weights\u001b[0;34m(self, model, global_round, lr)\u001b[0m\n\u001b[1;32m     62\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     63\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(log_probs, labels\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 64\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# log everything\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# if self.args.verbose and (batch_idx % 10 == 0):\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#     print('| Global Round : {} | Local Epoch : {} | [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m#         100. * batch_idx / len(self.trainloader), loss.item()))\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# self.logger.add_scalar('loss', loss.item())\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/anaconda_enviroment/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/anaconda_enviroment/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    local_weights, local_losses = [], []\n",
    "    global_model.train()\n",
    "    m = max(int(FRACTION*NUM_CLIENTS), 1) # number of clients for each round\n",
    "    global_weights = global_model.state_dict()\n",
    "    \n",
    "    set_of_clients = np.random.choice(range(NUM_CLIENTS), m, replace=False)\n",
    "    for client_idx in tqdm(set_of_clients):\n",
    "        print(f\"client {client_idx}\")\n",
    "        local_model = Client(dataset=train_dataset, idxs=list(clients[client_idx]),local_epochs=10, local_bs=10, device=DEVICE)\n",
    "        print(f\"updating weights for client {client_idx}\")\n",
    "        weights , loss = local_model.update_weights(model=copy.deepcopy(global_model), global_round=epoch, lr=lr)\n",
    "        local_weights.append(copy.deepcopy(weights)) \n",
    "        local_losses.append(copy.deepcopy(loss))\n",
    "    \n",
    "    # get the averaged weights\n",
    "    print(f'Averaging the model for epoch number {epoch}')\n",
    "    global_weights = average_weights(local_weights)\n",
    "    \n",
    "    # update global model with averaged weights\n",
    "    global_model.load_state_dict(global_weights)\n",
    "\n",
    "    # average of the losses\n",
    "    loss_avg = np.mean(local_losses)\n",
    "    train_loss.append(loss_avg)\n",
    "\n",
    "    # getting the average training accuracy over all clients at every epoch\n",
    "    print(f\"getting the average training accuracy over all clients at epoch number {epoch}\")\n",
    "    list_acc, list_loss = [], []\n",
    "    global_model.eval()\n",
    "    for client in range(NUM_CLIENTS):\n",
    "        local_model = Client(dataset=train_dataset, idxs=list(clients[client_idx]),local_epochs=10, local_bs=10, device=DEVICE)\n",
    "        acc, loss = local_model.test_model(model=global_model)\n",
    "        list_acc.append(acc)\n",
    "        list_loss.append(loss)\n",
    "    training_accuracy.append(np.mean(list_acc))\n",
    "\n",
    "    if epoch % EVERY == 0:\n",
    "        print(f\"EPOCH {epoch + 1}:\")\n",
    "        print(f'Average training loss: {np.mean(np.array(train_loss))}')\n",
    "        print('Train Accuracy: {:.2f}% \\n'.format(100*training_accuracy[-1]))\n",
    "    \n",
    "# Testing how the model is doing after all the traingin rounds\n",
    "global_model.eval()\n",
    "loss, total, correct = 0.0, 0.0, 0.0\n",
    "\n",
    "criterion = nn.NLLLoss().to(DEVICE)\n",
    "testloader = DataLoader(test_dataset, batch_size=128,\n",
    "                        shuffle=False)\n",
    "\n",
    "for batch_idx, (images, labels) in enumerate(testloader):\n",
    "    images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "    # Inference\n",
    "    outputs = global_model(images)\n",
    "    batch_loss = criterion(outputs, labels)\n",
    "    loss += batch_loss.item()\n",
    "\n",
    "    # Prediction\n",
    "    _, pred_labels = torch.max(outputs, 1)\n",
    "    pred_labels = pred_labels.view(-1)\n",
    "    correct += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "    total += len(labels)\n",
    "\n",
    "accuracy = correct/total\n",
    "print(f' \\n Results after {EPOCHS} global rounds of training:')\n",
    "print(\"|---- Avg Train Accuracy: {:.2f}%\".format(100*training_accuracy[-1]))\n",
    "print(\"|---- Test Accuracy: {:.2f}%\".format(100*accuracy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a887a05077574c1a3c0ad038b480e334bde0840f4a7b639e98601dedac24eb0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit ('anaconda_enviroment': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
